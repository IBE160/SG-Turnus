# backend/app/core/ai/exploratory_module.py

from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate
from langchain_core.messages import SystemMessage, AIMessage

class ExploratoryModule:
    """
    Module responsible for generating exploratory phrasing when the AI's
    confidence is low, to encourage the user to provide more information.
    """

    def __init__(self, model_name: str = "gpt-4o", temperature: float = 0.7):
        """
        Initializes the ExploratoryModule with an LLM and a prompt template.

        Args:
            model_name: The name of the OpenAI model to use.
            temperature: The sampling temperature for the LLM.
        """
        self.llm = ChatOpenAI(model_name=model_name, temperature=temperature)
        self.prompt = ChatPromptTemplate.from_messages(
            [
                SystemMessage(
                    content=(
                        "You are an AI assistant designed to help users explore their thoughts "
                        "when the system is uncertain about their input. Your goal is to offer "
                        "exploratory phrasing that gently probes for more information or helps "
                        "the user articulate their needs without being leading. "
                        "The phrasing should be open-ended, polite, and directly related to the user's input "
                        "and the inferred context."
                    )
                ),
                HumanMessagePromptTemplate.from_template(
                    "User input: \"{user_input}\"\n"
                    "Inferred key term: \"{key_term}\"\n"
                    "Inferred topic: \"{topic}\"\n\n"
                    "Based on this information, please generate an exploratory phrase to help the user elaborate. "
                    "Example: \"Could you tell me more about \'{key_term}\' in relation to \'{topic}\'?\""
                ),
            ]
        )

    def generate_phrasing(self, user_input: str, inferred_context: dict) -> str:
        """
        Generates an exploratory phrase using an LLM based on the user input and context.

        Args:
            user_input: The original input from the user.
            inferred_context: A dictionary containing inferred information,
                              such as key terms and the topic. Expected keys:
                              'key_term' and 'topic'.

        Returns:
            A formatted exploratory phrase generated by the LLM.
        """
        key_term = inferred_context.get("key_term")
        topic = inferred_context.get("topic")

        if not key_term or not topic:
            # Fallback if context is missing
            return "Could you please tell me more about what you're trying to understand?"

        chain = self.prompt | self.llm
        response_content = chain.invoke({
            "user_input": user_input,
            "key_term": key_term,
            "topic": topic
        }).content
        return response_content

# Example of how this might be used (requires OpenAI API key to be set up)
if __name__ == '__main__':
    # Ensure OPENAI_API_KEY environment variable is set
    import os
    if "OPENAI_API_KEY" not in os.environ:
        print("Please set the OPENAI_API_KEY environment variable.")
    else:
        exploratory_module = ExploratoryModule()
        user_query = "I'm confused about this part of the lecture."
        context = {"key_term": "this part", "topic": "lecture"}

        print("Generating exploratory phrasing...")
        phrasing = exploratory_module.generate_phrasing(user_query, context)
        print(f"Generated Phrasing: {phrasing}")

        # Example with missing context
        no_context_phrasing = exploratory_module.generate_phrasing("What is it?", {})
        print(f"\nNo context scenario: {no_context_phrasing}")